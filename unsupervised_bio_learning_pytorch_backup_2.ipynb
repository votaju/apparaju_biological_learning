{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables required for the algorithm\n",
    "\n",
    "learning_rate = 2e-2    # initial learning rate\n",
    "Kx = 10\n",
    "Ky = 10\n",
    "n_hidden = Kx*Ky        # number of hidden units that are displayed in Ky by Kx array\n",
    "mu = 0.0                # mean for gaussian distribution to initialize weights with\n",
    "sigma = 1.0             # standard deviation for gaussian distribution to initialize weights with\n",
    "n_epochs = 1000          # number of epochs\n",
    "batch_size = 100        # size of the minibatch\n",
    "precision = 1e-30       # parameter to control numerical precision of weight updates\n",
    "anti_hebbian_learning_strength = 0.4    # Strength of the anti-hebbian learning\n",
    "lebesgue_norm = 3.0                     # Lebesgue norm of the weights\n",
    "rank = 7                                # ranking parameter, must be integer that is bigger or equal than 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNSUPERVISED 'BIO' LEARNING ALGORITHM\n",
    "\n",
    "# Define function that performs the unsupervised learning and returns weights\n",
    "# that correspond to feature detectors.\n",
    "# Uses cuda if available.\n",
    "def get_unsupervised_weights(data, n_hidden, n_epochs, batch_size, learning_rate, precision, \n",
    "                             anti_hebbian_learning_strength, lebesgue_norm, rank):\n",
    "    print(\"Starting unsupervised bio-plausible training\")\n",
    "    \n",
    "    num_samples = data.shape[0]   # Number of samples/images.\n",
    "    num_features = data.shape[1]  # Number of pixels for each sample/image.\n",
    "    \n",
    "    # Initialize weights to be values drawn from gaussian distribution.\n",
    "    synapses = np.random.normal(mu, sigma, (n_hidden, num_features)).astype(np.float32)\n",
    "    weights = torch.from_numpy(synapses).to(device)\n",
    "\n",
    "    # The external loop runs over epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        eps = learning_rate * (1 - epoch / n_epochs)\n",
    "        #print(f'epoch learning rate: {eps}')\n",
    "\n",
    "        # Scramble the images and values. So that when making a\n",
    "        # mini batch, random values/images will be chosen on each iteration.\n",
    "        random_permutation_samples = np.random.permutation(num_samples)\n",
    "        shuffled_epoch_data = data[random_permutation_samples,:]\n",
    "\n",
    "        # Internal loop runs over minibatches    \n",
    "        for i in range(num_samples // batch_size):        \n",
    "            # For every minibatch the overlap with the data (tot_input) is \n",
    "            # calculated for each data point and each hidden unit.\n",
    "            mini_batch = shuffled_epoch_data[i*batch_size:(i+1)*batch_size,:].astype(np.float32)\n",
    "            mini_batch = torch.from_numpy(mini_batch).to(device)           \n",
    "            mini_batch = torch.transpose(mini_batch, 0, 1)\n",
    "\n",
    "            sign = torch.sign(weights)            \n",
    "            W = sign * torch.abs(weights) ** (lebesgue_norm - 1)    \n",
    "            # https://stackoverflow.com/questions/44524901/how-to-do-product-of-matrices-in-pytorch\n",
    "            tot_input_torch = torch.mm(W, mini_batch)\n",
    "\n",
    "            # The sorted strengths of the activations are stored in y. \n",
    "            # The variable yl stores the activations of the post synaptic cells - \n",
    "            # it is denoted by g(Q) in Eq 3 of 'Unsupervised Learning by Competing Hidden Units', see also Eq 9 and Eq 10.        \n",
    "            y_torch = torch.argsort(tot_input_torch, dim=0)            \n",
    "            yl_torch = torch.zeros((n_hidden, batch_size), dtype = torch.float).to(device)\n",
    "            yl_torch[y_torch[n_hidden-1,:], torch.arange(batch_size)] = 1.0\n",
    "            yl_torch[y_torch[n_hidden-rank], torch.arange(batch_size)] = -anti_hebbian_learning_strength\n",
    "\n",
    "            # The variable ds is the right hand side of Eq 3        \n",
    "            xx_torch = torch.sum(yl_torch * tot_input_torch,1)  \n",
    "            xx_torch = xx_torch.unsqueeze(1)                    \n",
    "            xx_torch = xx_torch.repeat(1, num_features)\n",
    "            ds_torch = torch.mm(yl_torch, torch.transpose(mini_batch, 0, 1)) - (xx_torch * weights)\n",
    "\n",
    "            # Update weights\n",
    "            # The weights are updated after each minibatch in a way so that the largest update \n",
    "            # is equal to the learning rate eps at that epoch.        \n",
    "            nc_torch = torch.max(torch.abs(ds_torch))\n",
    "            if nc_torch < precision: \n",
    "                nc_torch = precision            \n",
    "            weights += eps*(ds_torch/nc_torch)\n",
    "\n",
    "            #if (i+1) % 100 == 0:\n",
    "            #    print (f'Epoch [{epoch+1}/{n_epochs}], Step [{i+1}/{num_samples // batch_size}]')\n",
    "\n",
    "        print (f'Epoch [{epoch+1}/{n_epochs}]')\n",
    "        \n",
    "    print(\"Completed unsupervised bio-plausible training\")\n",
    "    return weights.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST...\n",
      "Done loading MNIST\n",
      "Number of samples: 60000\n",
      "Number of features: 784\n"
     ]
    }
   ],
   "source": [
    "# LOAD AND PREPARE MNIST DATA\n",
    "\n",
    "print(\"Loading MNIST...\")\n",
    "mat = scipy.io.loadmat('mnist_all.mat')\n",
    "print(\"Done loading MNIST\")\n",
    "#print(mat)\n",
    "\n",
    "Nc=10 # number of classes\n",
    "N=784 # number of pixels for each image. 28x28\n",
    "\n",
    "M=np.zeros((0,N))\n",
    "for i in range(Nc):\n",
    "    M=np.concatenate((M, mat['train'+str(i)]), axis=0)\n",
    "M=M/255.0\n",
    "\n",
    "data_mnist = M\n",
    "print(f'Number of samples: {data_mnist.shape[0]}')\n",
    "print(f'Number of features: {data_mnist.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD AND PREPARE CIFAR-10 DATA\n",
    "# REFERENCE: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "# Keeping here for reference. From link above.\n",
    "# As per the 'hidden competing units' paper, no need to Normalize as provided in the link.\n",
    "# The dataset has PILImage images of range [0, 1]. \n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "#transform = transforms.Compose(\n",
    "#    [transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# The CIFAR-10 dataset has PILImage images of range [0, 1]. \n",
    "# As mentioned in the 'hidden competing units' paper, \"no preprocessing of the data was used except that\n",
    "# each input image was normalized to be a unit vector in the 32x32x3 = 3072-dimensional space.\"\n",
    "# We transform the images to Tensors here, and normalize to unit vectors further on in this cell.\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                             download=True, transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "# This cell uses just the training data loader to initialize the CIFAR-10 dataset as\n",
    "# a unit vector in the 3072-dimensional space\n",
    "# TODO re-initialise these loaders when performing supervised training, and when testing.\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=25000)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset)\n",
    "\n",
    "cifar_classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Test function to display an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Display some random training images\n",
    "#train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1)\n",
    "#dataiter = iter(train_loader)\n",
    "#images, labels = dataiter.next()\n",
    "#print(images.shape)\n",
    "#print(labels.shape)\n",
    "#imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "num_classes=10 # number of classes\n",
    "num_pixels=32*32 # number of pixels for each image. 32x32\n",
    "num_channels = 3 # RGB\n",
    "M=np.zeros((0, num_pixels*num_channels)) #Â Want 3072-dimensional space\n",
    "\n",
    "# Like for MNIST, ensure M has shape (num_samples, 3072)\n",
    "# Do in a couple iterations, each handling half of the training data\n",
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    images = torch.reshape(images, (25000,-1)).numpy()\n",
    "    M=np.concatenate((M, images), axis=0)\n",
    "\n",
    "data = M\n",
    "\n",
    "# L2-normalize the training samples to unit vectors.\n",
    "data_cifar = preprocessing.normalize(data, norm='l2')\n",
    "print(f'CIFAR-10 training data shape: {data_cifar.shape}')\n",
    "print(f'Number of CIFAR-10 training samples: {data_cifar.shape[0]}')\n",
    "print(f'Number of CIFAR-10 features: {data_cifar.shape[1]}')\n",
    "\n",
    "\n",
    "# Test print normalized data\n",
    "#sample_data = data_cifar[0]\n",
    "#print(sample_data.shape)\n",
    "#print(\"Magnitude of the normalized vector:\")\n",
    "#print(np.linalg.norm(sample_data))\n",
    "#print(sample_data)\n",
    "#print(np.amax(data_cifar))\n",
    "#print(np.amin(data_cifar))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD AND PREPARE CIFAR-10 DATA\n",
    "# REFERENCE: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "# Keeping here for reference. From link above.\n",
    "# As per the 'hidden competing units' paper, no need to Normalize as provided in the link.\n",
    "# The dataset has PILImage images of range [0, 1]. \n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "#transform = transforms.Compose(\n",
    "#    [transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# The CIFAR-10 dataset has PILImage images of range [0, 1]. \n",
    "# As mentioned in the 'hidden competing units' paper, \"no preprocessing of the data was used except that\n",
    "# each input image was normalized to be a unit vector in the 32x32x3 = 3072-dimensional space.\"\n",
    "# We transform the images to Tensors here, and normalize to unit vectors further on in this cell.\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                             download=True, transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "\n",
    "cifar_classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Test function to display an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Display some random training images\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1)\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "#imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting unsupervised bio-plausible training\n",
      "Epoch [1/1000]\n",
      "Epoch [2/1000]\n",
      "Epoch [3/1000]\n",
      "Epoch [4/1000]\n",
      "Epoch [5/1000]\n",
      "Epoch [6/1000]\n",
      "Epoch [7/1000]\n",
      "Epoch [8/1000]\n",
      "Epoch [9/1000]\n",
      "Epoch [10/1000]\n",
      "Epoch [11/1000]\n",
      "Epoch [12/1000]\n",
      "Epoch [13/1000]\n",
      "Epoch [14/1000]\n",
      "Epoch [15/1000]\n",
      "Epoch [16/1000]\n",
      "Epoch [17/1000]\n",
      "Epoch [18/1000]\n",
      "Epoch [19/1000]\n",
      "Epoch [20/1000]\n",
      "Epoch [21/1000]\n",
      "Epoch [22/1000]\n",
      "Epoch [23/1000]\n",
      "Epoch [24/1000]\n",
      "Epoch [25/1000]\n",
      "Epoch [26/1000]\n",
      "Epoch [27/1000]\n",
      "Epoch [28/1000]\n",
      "Epoch [29/1000]\n",
      "Epoch [30/1000]\n",
      "Epoch [31/1000]\n",
      "Epoch [32/1000]\n",
      "Epoch [33/1000]\n",
      "Epoch [34/1000]\n",
      "Epoch [35/1000]\n",
      "Epoch [36/1000]\n",
      "Epoch [37/1000]\n",
      "Epoch [38/1000]\n",
      "Epoch [39/1000]\n",
      "Epoch [40/1000]\n",
      "Epoch [41/1000]\n",
      "Epoch [42/1000]\n",
      "Epoch [43/1000]\n",
      "Epoch [44/1000]\n",
      "Epoch [45/1000]\n",
      "Epoch [46/1000]\n",
      "Epoch [47/1000]\n",
      "Epoch [48/1000]\n",
      "Epoch [49/1000]\n",
      "Epoch [50/1000]\n",
      "Epoch [51/1000]\n",
      "Epoch [52/1000]\n",
      "Epoch [53/1000]\n",
      "Epoch [54/1000]\n",
      "Epoch [55/1000]\n",
      "Epoch [56/1000]\n",
      "Epoch [57/1000]\n",
      "Epoch [58/1000]\n",
      "Epoch [59/1000]\n",
      "Epoch [60/1000]\n",
      "Epoch [61/1000]\n",
      "Epoch [62/1000]\n",
      "Epoch [63/1000]\n",
      "Epoch [64/1000]\n",
      "Epoch [65/1000]\n",
      "Epoch [66/1000]\n",
      "Epoch [67/1000]\n",
      "Epoch [68/1000]\n",
      "Epoch [69/1000]\n",
      "Epoch [70/1000]\n",
      "Epoch [71/1000]\n",
      "Epoch [72/1000]\n",
      "Epoch [73/1000]\n",
      "Epoch [74/1000]\n",
      "Epoch [75/1000]\n",
      "Epoch [76/1000]\n",
      "Epoch [77/1000]\n",
      "Epoch [78/1000]\n",
      "Epoch [79/1000]\n",
      "Epoch [80/1000]\n",
      "Epoch [81/1000]\n",
      "Epoch [82/1000]\n",
      "Epoch [83/1000]\n",
      "Epoch [84/1000]\n",
      "Epoch [85/1000]\n",
      "Epoch [86/1000]\n",
      "Epoch [87/1000]\n",
      "Epoch [88/1000]\n",
      "Epoch [89/1000]\n",
      "Epoch [90/1000]\n",
      "Epoch [91/1000]\n",
      "Epoch [92/1000]\n",
      "Epoch [93/1000]\n",
      "Epoch [94/1000]\n",
      "Epoch [95/1000]\n",
      "Epoch [96/1000]\n",
      "Epoch [97/1000]\n",
      "Epoch [98/1000]\n",
      "Epoch [99/1000]\n",
      "Epoch [100/1000]\n",
      "Epoch [101/1000]\n",
      "Epoch [102/1000]\n",
      "Epoch [103/1000]\n",
      "Epoch [104/1000]\n",
      "Epoch [105/1000]\n",
      "Epoch [106/1000]\n",
      "Epoch [107/1000]\n",
      "Epoch [108/1000]\n",
      "Epoch [109/1000]\n",
      "Epoch [110/1000]\n",
      "Epoch [111/1000]\n",
      "Epoch [112/1000]\n",
      "Epoch [113/1000]\n",
      "Epoch [114/1000]\n",
      "Epoch [115/1000]\n",
      "Epoch [116/1000]\n",
      "Epoch [117/1000]\n",
      "Epoch [118/1000]\n",
      "Epoch [119/1000]\n",
      "Epoch [120/1000]\n",
      "Epoch [121/1000]\n",
      "Epoch [122/1000]\n",
      "Epoch [123/1000]\n",
      "Epoch [124/1000]\n",
      "Epoch [125/1000]\n",
      "Epoch [126/1000]\n",
      "Epoch [127/1000]\n",
      "Epoch [128/1000]\n",
      "Epoch [129/1000]\n",
      "Epoch [130/1000]\n",
      "Epoch [131/1000]\n",
      "Epoch [132/1000]\n",
      "Epoch [133/1000]\n",
      "Epoch [134/1000]\n",
      "Epoch [135/1000]\n",
      "Epoch [136/1000]\n",
      "Epoch [137/1000]\n",
      "Epoch [138/1000]\n",
      "Epoch [139/1000]\n",
      "Epoch [140/1000]\n",
      "Epoch [141/1000]\n",
      "Epoch [142/1000]\n",
      "Epoch [143/1000]\n",
      "Epoch [144/1000]\n",
      "Epoch [145/1000]\n",
      "Epoch [146/1000]\n",
      "Epoch [147/1000]\n",
      "Epoch [148/1000]\n",
      "Epoch [149/1000]\n",
      "Epoch [150/1000]\n",
      "Epoch [151/1000]\n",
      "Epoch [152/1000]\n",
      "Epoch [153/1000]\n",
      "Epoch [154/1000]\n",
      "Epoch [155/1000]\n",
      "Epoch [156/1000]\n",
      "Epoch [157/1000]\n",
      "Epoch [158/1000]\n",
      "Epoch [159/1000]\n",
      "Epoch [160/1000]\n",
      "Epoch [161/1000]\n",
      "Epoch [162/1000]\n",
      "Epoch [163/1000]\n",
      "Epoch [164/1000]\n",
      "Epoch [165/1000]\n",
      "Epoch [166/1000]\n",
      "Epoch [167/1000]\n",
      "Epoch [168/1000]\n",
      "Epoch [169/1000]\n",
      "Epoch [170/1000]\n",
      "Epoch [171/1000]\n",
      "Epoch [172/1000]\n",
      "Epoch [173/1000]\n",
      "Epoch [174/1000]\n",
      "Epoch [175/1000]\n",
      "Epoch [176/1000]\n",
      "Epoch [177/1000]\n",
      "Epoch [178/1000]\n",
      "Epoch [179/1000]\n",
      "Epoch [180/1000]\n",
      "Epoch [181/1000]\n",
      "Epoch [182/1000]\n",
      "Epoch [183/1000]\n",
      "Epoch [184/1000]\n"
     ]
    }
   ],
   "source": [
    "# RUN UNSUPERVISED 'BIO' LEARNING ALGORITHM for MNIST\n",
    "\n",
    "# Calculates weights for data and provided number of hidden units (given other configuration)\n",
    "weights_mnist = get_unsupervised_weights(data_mnist, n_hidden, n_epochs, batch_size, learning_rate, precision, \n",
    "                                         anti_hebbian_learning_strength, lebesgue_norm, rank)\n",
    "print(weights_mnist.shape)\n",
    "print(weights_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# RUN UNSUPERVISED 'BIO' LEARNING ALGORITHM for CIFAR\n",
    "\n",
    "# Calculates weights for data and provided number of hidden units (given other configuration)\n",
    "weights_cifar = get_unsupervised_weights(data_cifar, n_hidden, n_epochs, batch_size, learning_rate, precision, \n",
    "                                         anti_hebbian_learning_strength, lebesgue_norm, rank)\n",
    "print(weights_cifar.shape)\n",
    "print(weights_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Draw MNIST weights/feature detectors generated by unsupervised bio algo\n",
    "\n",
    "# REFERENCED FROM: https://github.com/DimaKrotov/Biological_Learning\n",
    "# To draw a heatmap of the weights a helper function is created\n",
    "\n",
    "def draw_weights(synapses, Kx, Ky):\n",
    "    print(synapses.shape) # (100, 784)\n",
    "    print(synapses)\n",
    "    yy=0\n",
    "    HM=np.zeros((28*Ky,28*Kx))\n",
    "    print(HM.shape) # (280, 280)\n",
    "    for y in range(Ky):\n",
    "        for x in range(Kx):\n",
    "            \n",
    "            shit = synapses[yy,:]\n",
    "            shit_reshape = synapses[yy,:].reshape(28,28)\n",
    "            \n",
    "            #print(synapses.shape)     # (100, 784)\n",
    "            #print(shit.shape)         # (784,)\n",
    "            #print(shit_reshape.shape) # (28, 28)\n",
    "            \n",
    "            HM[y*28:(y+1)*28,x*28:(x+1)*28]=synapses[yy,:].reshape(28,28)\n",
    "            \n",
    "            #print(HM.shape)\n",
    "            \n",
    "            yy += 1\n",
    "    plt.clf()\n",
    "    nc=np.amax(np.absolute(HM))\n",
    "    print(\"####\")\n",
    "    print(HM.shape)\n",
    "    print(HM)\n",
    "    im=plt.imshow(HM,cmap='bwr',vmin=-nc,vmax=nc)\n",
    "    fig.colorbar(im,ticks=[np.amin(HM), 0, np.amax(HM)])\n",
    "    plt.axis('off')\n",
    "    fig.canvas.draw() \n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "fig=plt.figure(figsize=(12.9,10))\n",
    "#draw_weights(weights, Kx, Ky)\n",
    "draw_weights(weights_mnist, Kx, Ky)\n",
    "print(\"Fin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Draw CIFAR-10 weights/feature detectors generated by unsupervised bio algo\n",
    "\n",
    "def draw_weights(synapses, Kx, Ky):\n",
    "    print(synapses)\n",
    "    print(synapses.shape) # (100, 3072)\n",
    "    yy=0\n",
    "    HM=np.zeros((32*Ky,32*Kx,3))\n",
    "    print(HM.shape) # (320, 320, 3)\n",
    "    for y in range(Ky):\n",
    "        for x in range(Kx):\n",
    "\n",
    "            shit = synapses[yy,:]\n",
    "            shit_reshape = synapses[yy,:].reshape(3,32,32)\n",
    "\n",
    "            #print(synapses.shape)   # (100, 3072)\n",
    "            #print(shit.shape)          # (3072,)\n",
    "            #print(shit_reshape.shape)  # (3, 32, 32)\n",
    "\n",
    "            #HM[y*28:(y+1)*28,x*28:(x+1)*28]=synapses[yy,:].reshape(28,28)\n",
    "            HM[y*32:(y+1)*32,x*32:(x+1)*32,:]=synapses[yy,:].reshape(32,32,3)\n",
    "\n",
    "            #HM[z, y*32:(y+1)*32,x*32:(x+1)*32]=synapses[yy,:].reshape(3,32,32)\n",
    "            yy += 1\n",
    "    print(\"Done with the fucking loop\")\n",
    "    plt.clf()\n",
    "    nc=np.amax(np.absolute(HM))\n",
    "    im=plt.imshow(HM[:,:,0],cmap='bwr',vmin=-nc,vmax=nc)\n",
    "    fig.colorbar(im,ticks=[np.amin(HM), 0, np.amax(HM)])\n",
    "    plt.axis('off')\n",
    "    fig.canvas.draw()\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "fig=plt.figure(figsize=(12.9,10))\n",
    "draw_weights(weights_cifar, Kx, Ky)\n",
    "print(\"Fin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THIS BLOCK FOR DEBUGGING PURPOSES ONLY\n",
    "\n",
    "# Contains data loading and whole bio learning in one block of code.\n",
    "# Plots the feature detectors at the end of training.\n",
    "\n",
    "# LOAD AND PREPARE DATA\n",
    "\n",
    "print(\"Loading MNIST...\")\n",
    "mat = scipy.io.loadmat('mnist_all.mat')\n",
    "print(\"Done loading MNIST\")\n",
    "\n",
    "Nc=10 # output nodes\n",
    "N=784 # number of pixels for each image. 28x28\n",
    "\n",
    "M=np.zeros((0,N))\n",
    "for i in range(Nc):\n",
    "    M=np.concatenate((M, mat['train'+str(i)]), axis=0)\n",
    "M=M/255.0\n",
    "\n",
    "data = M\n",
    "num_samples = data.shape[0]   # 60000 training and validation examples. Number of samples\n",
    "num_features = data.shape[1]  # number of pixels for each image. 28x28. Also: num_samples, num_pixels..\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# UNSUPERVISED 'BIO' LEARNING ALGORITHM\n",
    "\n",
    "# Initialize weights to be values drawn from gaussian distribution.\n",
    "synapses = np.random.normal(mu, sigma, (n_hidden, N)).astype(np.float32)\n",
    "weights = torch.from_numpy(synapses).to(device)\n",
    "\n",
    "# The external loop runs over epochs\n",
    "for epoch in range(n_epochs):\n",
    "    eps = learning_rate * (1 - epoch / n_epochs)\n",
    "    #print(f'epoch learning rate: {eps}')\n",
    "    \n",
    "    # Scramble the images and values. So that when making a\n",
    "    # mini batch, random values/images will be chosen on each iteration.\n",
    "    random_permutation_samples = np.random.permutation(num_samples)\n",
    "    shuffled_epoch_data = data[random_permutation_samples,:]\n",
    "    \n",
    "    # Internal loop runs over minibatches    \n",
    "    for i in range(num_samples // batch_size):        \n",
    "        # For every minibatch the overlap with the data (tot_input) is \n",
    "        # calculated for each data point and each hidden unit.\n",
    "        mini_batch = shuffled_epoch_data[i*batch_size:(i+1)*batch_size,:].astype(np.float32)\n",
    "        mini_batch = torch.from_numpy(mini_batch).to(device)           \n",
    "        mini_batch = torch.transpose(mini_batch, 0, 1)\n",
    "        \n",
    "        sign = torch.sign(weights)            \n",
    "        W = sign * torch.abs(weights) ** (lebesgue_norm - 1)    \n",
    "        # https://stackoverflow.com/questions/44524901/how-to-do-product-of-matrices-in-pytorch\n",
    "        tot_input_torch = torch.mm(W, mini_batch)\n",
    "                \n",
    "        # The sorted strengths of the activations are stored in y. \n",
    "        # The variable yl stores the activations of the post synaptic cells - \n",
    "        # it is denoted by g(Q) in Eq 3 of 'Unsupervised Learning by Competing Hidden Units', see also Eq 9 and Eq 10.        \n",
    "        y_torch = torch.argsort(tot_input_torch, dim=0)            \n",
    "        yl_torch = torch.zeros((n_hidden, batch_size), dtype = torch.float).to(device)\n",
    "        yl_torch[y_torch[n_hidden-1,:], torch.arange(batch_size)] = 1.0\n",
    "        yl_torch[y_torch[n_hidden-rank], torch.arange(batch_size)] = -anti_hebbian_learning_strength\n",
    "        \n",
    "        # The variable ds is the right hand side of Eq 3        \n",
    "        xx_torch = torch.sum(yl_torch * tot_input_torch,1)  \n",
    "        xx_torch = xx_torch.unsqueeze(1)                    \n",
    "        xx_torch = xx_torch.repeat(1, num_features)\n",
    "        ds_torch = torch.mm(yl_torch, torch.transpose(mini_batch, 0, 1)) - (xx_torch * weights)\n",
    "        \n",
    "        # Update weights\n",
    "        # The weights are updated after each minibatch in a way so that the largest update \n",
    "        # is equal to the learning rate eps at that epoch.        \n",
    "        nc_torch = torch.max(torch.abs(ds_torch))\n",
    "        if nc_torch < precision: \n",
    "            nc_torch = precision            \n",
    "        weights += eps*(ds_torch/nc_torch)\n",
    "        \n",
    "        #if (i+1) % 100 == 0:\n",
    "        #    print (f'Epoch [{epoch+1}/{n_epochs}], Step [{i+1}/{num_samples // batch_size}]')\n",
    "        \n",
    "    print (f'Epoch [{epoch+1}/{n_epochs}]')\n",
    "    #draw_weights(weights.numpy(), Kx, Ky)\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "fig=plt.figure(figsize=(12.9,10))\n",
    "draw_weights(weights.cpu().numpy(), Kx, Ky)\n",
    "print(\"Fin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
